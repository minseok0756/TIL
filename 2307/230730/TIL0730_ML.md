## ML

### 데이터 전처리
- 결손값(Null, NaN)은 허용되지 않는다.
- 고정된 다른 값으로 변환해야 한다.
- Null값이 적으면 평균값 등으로 간단히 대체 가능
- Null이 대부분이면 드롭하는 것이 좋다.
- 애매한 경우(기준은 없음) 엄무 로직 등을 검토해서 정밀한 대체값을 선청해야한다.

<br>

- 사이킷런의 머신러닝 알고리즘은 문자열 값을 입력값으로 허용하지 않는다.
- 인코딩해서 숫자형으로 변환해아 함

<br>

- 데이터 인코딩
    - 레이블 인코딩
    - 카테고리 피처를 코드형 숫자 값으로 변환하는 것
    - LabelEncoder()
    - .fit(인코딩할 데이터) / .transform(인코딩할 데이터)
    - .classes_ - 인코딩 클래스 확인
    - .inverse_transform() - 인코딩된 값을 다시 디코딩
    - 단점 - 인코딩이 일괄적인 숫자 값으로 변환되면서 단순히 카테고리를 나타내는 숫자 값의 크고 작음에 대한 특성이 학습에 영향(가중치가 더 부여)을 미친다.
    - 선형 회귀같은 알고리즘에는 적용하지 않아야한다.
    - 트리계열 알고리즘은 문제 없다.
    - 해결 - 원-핫 인코딩

    <br>

    - 원-핫 인코딩
    - OneHotEncoder()
    - .fit(인코딩할 데이터) - 인코딩할 데이터는 반드시 2차원 데이터
    - .transform(인코딩할 데이터)
    - .toarray() - 변환한 결과는 희소행렬이므로 toarray()를 이용해 밀집 행렬로 변환
    - pd.get_dummies() - 판다스에서 원-핫 인코딩 지원. OneHotencoder와 다르게 문자열 카테고리 값을 숫자 형으로 변환할 필요없이 바로 변환할 수 있다.

<br>

- 피처 스케일링과 정규화
- 서로 다른 변수의 값 범위를 일정한 수준으로 맞추는 작업

<br>

- 표준화 - 평균이 0, 분산이 1인 가우시안 정규 분포를 가진 값으로 변환
- 정규화 - 서로 다른 피처의 크기를 통일하기 위해 크기를 변환. 개별 데이터의 크기를 모두 똑같은 단위로 변경

<br>

- StandardScaler(표준화)
- 서포트 벡터 머신, 선형 회귀, 로지스틱 회귀는 데이터가 가우시안 분포를 가지고 있다고 가정하고 구현됐기 때문에 사전에 표준화를 적용하는 것은 예측 성능 향상에 중요한 요소가 될 수 있다.
- StandardScaler()
- .fit(스케일링할 데이터) / .transform(스케일링할 데이터) - 스케일링할 데이터는 반드시 2차원 데이터

<br>

- MinMaxScaler(정규화)
- 데이터 분포가 가우시안 분포가 아닐 경우 적용해 볼 수 있다.
- MinMaxScaler()
- .fit(스케일링할 데이터) / .transform(스케일링할 데이터) -스케일링할 데이터는 반드시 2차원 데이터

<br>

- 학습 데이터와 테스트 데이터의 스케일링 변환 시 유의점
- Scaler 객체를 이용해 학습 데이터 세트로 fit과 transform을 적용하면 테스트 데이터 세트로는 다시 fit을 수행하지 않고 학습 데이터 세트로 fit을 수행한 결과를 이용해 transform 변환을 적용해야 한다.
- 가능하다면 전체 데이터의 스케일링 변환을 적용한 뒤 데이터 세트 분리 권장

<br>

- 139p
- LogisticRegression의 생성 인자로 입력된 solver='liblinear'는 로지스틱 회귀의 최적화 알고리즘을 liblinear로 설정하는 것이다.
- 일반적으로 작은 데이터 세트에서의 이진 분류는 liblinear가 성능이 약간 더 좋은 경향이 있다.

<br>

## 평가
- 정확도
- ML 모델의 성능을 왜곡할 수 있다.
- 불균형한 레이블 값 분포에서 ML 모델의 성능을 판단할 경우 적합한 평가 지표가 아니다.

<br>

- 오차행렬
- 이진 분류의 예측 오류가 얼마인지와 더불어 어떤 유형의 예측 오류가 발생하고 있는지를 함께 나타내는 지표
- 일반적으로 불균형한 레이블 클래스를 가지는 이진 분류 모델에서는 많은 데이터 중에서 중점적으로 찾아야 하는 매우 적은 수의 결과값에 Positive를 설정해 1값을 부여하고, 그러허지 않은 경우는 Negative로 0값을 부여하는 경우가 많다.
- confusion_matrix()

<br>

- 정밀도와 재현율(민감도, TPR)
- Positive 데이터 세트의 예측 성능에 좀 더 초점을 맞춘 평가 지표이다.
- 재현율은 실제 Positive 양성 데이터를 Negative로 잘못 판단하게 되면 업무상 큰 영향이 발생하는 경우 중요 지표이다.
- precision_score()
- 정밀도는 실제 Negative 음성 데이터를 Positive로 잘못 판단하게 되면 업무상 큰 영향이 발생하는 경우 중요 지표이다.
- recall_score()

    - 156p
    - LogisticRegression 객체의 생성 인자로 입력되는 solver='liblinear'는 로지스틱 회귀의 최적화 알고리즘 유형을 지정하는 것이다.
    - 보통 작은 데이터 세트의 이진 분류인 경우 solver는 liblinear가 약간 성능이 좋은 경향이 있다.
    - solver의 기본값은 lbfgs이며 데이터 세트가 상대적으로 크고 다중 분류인 경우 적합하다.

<br>

- 정밀도/재현율 트레이드오프
- 상호 보완적인 평가 지표이기 때문에 어느 한 쪽은 강제로 높이면 다른 하나의 수치는 떨어지기 쉽다.
- 분류의 결정 임계값(Threshold)을 조정해 정밀도 또는 재현율의 수치를 높일 수 있다.
- 사이킷런 분류 알고리즘은 예측 데이터가 특정 레이블에 속하는지를 계산하기 위해 먼저 개별 레이블별로 결정 확률을 구한다.(예측 데이터별로 각각 구한다.)
- 일반적으로 이진 분류에서는 임계값을 0.5(50%)로 정하고 이 기준값보다 확률이 크면 Positive, 작으면 Negative로 결정한다.
- 개별 데이터 별로 예측 확률을 반환하는 메서드인 predict_proba()를 제공한다.
- 학습이 완료된 사이킷런 Classifier 객체에서 호출이 가능하다.
- 테스트 피처 데이터 세트를 파라미터로 입력해주면 테스트 피처 레코드의 개별 클래스 예측 확률을 반환한다.

    - Binarizer 클래스
    - 입력된 ndarray의 값을 지정된 threshold보다 같거나 작으면 0값으로, 크면 1값으로 변환해 반환한다.
    - threshold값을 변경하면서 정밀도/재현율 트레이드오프를 확인할 수 있다.
    - Binarizer(threshold)
    - .fit(2차원 데이터) / transform(2차원 데이터) - Positive 예측확률을 2차원 데이터로 변환하여 입력한다.

- precision_recall_curve(y_true, proba_pred)
    - proba_pred - Positive 예측확률값을 입력
- 리턴 - (임계값별)정밀도, (임계값별)재현율, 임계값

<br>

- F1 스코어
- 정밀도와 재현율을 결합
- f1_score()

<br>

- ROC 곡선과 AUC
- FPR(False Positive Rate)이 변할 때 TPR(True Positive Rate)이 어떻게 변하는지를 나타내는 곡선
- TPR(True Positive Rate) = 재현율 = 민감도
- TNR(True Negative Rate) = 특이성(Specificity)
    - 실제 Negative 데이터 중 제대로 예측한 데이터 비율
- FPR(False Positive Rate) = 1 - 특이성
- roc_curve(y_true, y_score) - ROC 곡선을 구하기 위한 API
    - y_score - 주로 Positive 예측확률을 입력(2차원으로 변환하지 않는다.)
- 리턴 - FPR, TPR, thresholds

<br>

- AUC
- ROC 곡선 밑의 면적을 구한 값
- 1에 가까울수록 좋은 수치이다.
- roc_auc_score()