{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ce2982f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8700c69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('practice').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2aab0de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.4.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a9bdaa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "strings = spark.read.text('README.md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ace4762c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------+\n",
      "|value                                                                                             |\n",
      "+--------------------------------------------------------------------------------------------------+\n",
      "|# Apache Spark                                                                                    |\n",
      "|                                                                                                  |\n",
      "|Spark is a unified analytics engine for large-scale data processing. It provides                  |\n",
      "|high-level APIs in Scala, Java, Python, and R, and an optimized engine that                       |\n",
      "|supports general computation graphs for data analysis. It also supports a                         |\n",
      "|rich set of higher-level tools including Spark SQL for SQL and DataFrames,                        |\n",
      "|pandas API on Spark for pandas workloads, MLlib for machine learning, GraphX for graph processing,|\n",
      "|and Structured Streaming for stream processing.                                                   |\n",
      "|                                                                                                  |\n",
      "|<https://spark.apache.org/>                                                                       |\n",
      "+--------------------------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "strings.show(10, truncate=False)\n",
    "# 10줄을 보여줘!\n",
    "# truncate=False: 문자열이 길어도 자르지 말고 보여줘!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f6501d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered = strings.filter(strings.value.contains('Spark'))\n",
    "filtered.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af9bbcf",
   "metadata": {},
   "source": [
    "# 쿠키 몬스터를 위한 M&M 세기\n",
    "- 여러 주(state) 출신 학생들에게 상으로 쿠키 제공\n",
    "- 쿠키는 M&M을 사용하여 만들어짐\n",
    "- 서로 다른 주에 사는 학생들에게 적절한 비율로 쿠키가 주어지는지 확인하고 싶다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b1b28809",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Usage: mmcount <file>\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "-1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m -1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if len(sys.argv) != 2:\n",
    "        print('Usage: mmcount <file>', file=sys.stderr)\n",
    "        sys.exit(-1)\n",
    "        \n",
    "    # SparkSession API를 써서 SparkSession 객체를 만든다.\n",
    "    # JVM마다 하나만 존재할 수 있다.\n",
    "    spark = (SparkSession\n",
    "            .builder\n",
    "            .appName('PythonMnMCount')\n",
    "            .getOrCreate())\n",
    "    \n",
    "    # 명령행 인자에서 M&M 데이터가 들어 있는 파일 이름을 얻는다.\n",
    "    mnm_file = sys.argv[1]\n",
    "    \n",
    "    # 스키마 추론과 쉼표로 구분된 칼럼 이름이 제공되는 헤더가 있음을\n",
    "    # 지정해주고 CSV 포맷으로 파일을 읽어 들여 데이터 프레임에 저장한다.\n",
    "    mnm_df = (spark.read.format('csv')\n",
    "             .option('header', 'true')\n",
    "             .option('inferSchema', 'true')\n",
    "             .load(mnm_file))\n",
    "    \n",
    "    count_mnm_df = (mnm_df\n",
    "                   .select('State', 'Color', 'Count')\n",
    "                   .groupBy('State', 'Color')\n",
    "                   .sum('Count')\n",
    "                   .orderBy('sum(Count)', ascending=False))\n",
    "    \n",
    "    # show()는 액션이므로 위의 쿼리 내용들이 시작되게 된다는 점에 주목하자.\n",
    "    count_mnm_df.show(n=60, truncate=False)\n",
    "    print('Total Rows = %d' % (count_mnm_df.count()))\n",
    "    \n",
    "    # 위 코드는 모든 주에 대한 집계를 계산한것이다.\n",
    "    # 캘리포니아(CA)에 대해 보기를 원한다면?\n",
    "    ca_count_mnm_df = (mnm_df\n",
    "                       .select('State', 'Color', 'Count')\n",
    "                       .where(mnm_df.State == 'CA')\n",
    "                       .groupBy('State', 'Color')\n",
    "                       .sum('Count')\n",
    "                       .orderBy('sum(Count)', ascending=False))\n",
    "    \n",
    "    ca_count_mnm_df.show(n=10, truncate=False)\n",
    "    \n",
    "    # SparkSession을 멈춘다\n",
    "    spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac1cc80",
   "metadata": {},
   "source": [
    "선호하는 편집기를 써서 mnmcount.py라는 이름의 파일을 만들어 위 파이썬 코드를 입력하고 mnm_dataset.csv를 다운로드해 bin 디렉터리의 submit-spark 스크립트로 스파크 잡을 제출하라는데 어떻게 하는지 모르겠음. 리눅스나 맥 OS로 진행하는 책이라 쥬피터노트북으로 진행하는데 제한이 있을듯 <br>\n",
    "csv파일을 다운받고 직접 실행해본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a59d7791",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+----------+\n",
      "|State|Color |sum(Count)|\n",
      "+-----+------+----------+\n",
      "|CA   |Yellow|100956    |\n",
      "|WA   |Green |96486     |\n",
      "|CA   |Brown |95762     |\n",
      "|TX   |Green |95753     |\n",
      "|TX   |Red   |95404     |\n",
      "|CO   |Yellow|95038     |\n",
      "|NM   |Red   |94699     |\n",
      "|OR   |Orange|94514     |\n",
      "|WY   |Green |94339     |\n",
      "|NV   |Orange|93929     |\n",
      "|TX   |Yellow|93819     |\n",
      "|CO   |Green |93724     |\n",
      "|CO   |Brown |93692     |\n",
      "|CA   |Green |93505     |\n",
      "|NM   |Brown |93447     |\n",
      "|CO   |Blue  |93412     |\n",
      "|WA   |Red   |93332     |\n",
      "|WA   |Brown |93082     |\n",
      "|WA   |Yellow|92920     |\n",
      "|NM   |Yellow|92747     |\n",
      "|NV   |Brown |92478     |\n",
      "|TX   |Orange|92315     |\n",
      "|AZ   |Brown |92287     |\n",
      "|AZ   |Green |91882     |\n",
      "|WY   |Red   |91768     |\n",
      "|AZ   |Orange|91684     |\n",
      "|CA   |Red   |91527     |\n",
      "|WA   |Orange|91521     |\n",
      "|NV   |Yellow|91390     |\n",
      "|UT   |Orange|91341     |\n",
      "|NV   |Green |91331     |\n",
      "|NM   |Orange|91251     |\n",
      "|NM   |Green |91160     |\n",
      "|WY   |Blue  |91002     |\n",
      "|UT   |Red   |90995     |\n",
      "|CO   |Orange|90971     |\n",
      "|AZ   |Yellow|90946     |\n",
      "|TX   |Brown |90736     |\n",
      "|OR   |Blue  |90526     |\n",
      "|CA   |Orange|90311     |\n",
      "|OR   |Red   |90286     |\n",
      "|NM   |Blue  |90150     |\n",
      "|AZ   |Red   |90042     |\n",
      "|NV   |Blue  |90003     |\n",
      "|UT   |Blue  |89977     |\n",
      "|AZ   |Blue  |89971     |\n",
      "|WA   |Blue  |89886     |\n",
      "|OR   |Green |89578     |\n",
      "|CO   |Red   |89465     |\n",
      "|NV   |Red   |89346     |\n",
      "|UT   |Yellow|89264     |\n",
      "|OR   |Brown |89136     |\n",
      "|CA   |Blue  |89123     |\n",
      "|UT   |Brown |88973     |\n",
      "|TX   |Blue  |88466     |\n",
      "|UT   |Green |88392     |\n",
      "|OR   |Yellow|88129     |\n",
      "|WY   |Orange|87956     |\n",
      "|WY   |Yellow|87800     |\n",
      "|WY   |Brown |86110     |\n",
      "+-----+------+----------+\n",
      "\n",
      "Total Rows = 60\n",
      "+-----+------+----------+\n",
      "|State|Color |sum(Count)|\n",
      "+-----+------+----------+\n",
      "|CA   |Yellow|100956    |\n",
      "|CA   |Brown |95762     |\n",
      "|CA   |Green |93505     |\n",
      "|CA   |Red   |91527     |\n",
      "|CA   |Orange|90311     |\n",
      "|CA   |Blue  |89123     |\n",
      "+-----+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('mnm').getOrCreate()\n",
    "\n",
    "mnm_df = (spark.read.format('csv')\n",
    "         .option('header', 'true')\n",
    "         .option('inferSchema', 'true')\n",
    "         .load('mnm_dataset.csv'))\n",
    "\n",
    "count_mnm_df = (mnm_df\n",
    "               .select('State', 'Color', 'Count')\n",
    "               .groupBy('State', 'Color')\n",
    "               .sum('Count')\n",
    "               .orderBy('sum(Count)', ascending=False))\n",
    "\n",
    "# show()는 액션이므로 위의 쿼리 내용들이 시작되게 된다는 점에 주목하자.\n",
    "count_mnm_df.show(n=60, truncate=False)\n",
    "print('Total Rows = %d' % (count_mnm_df.count()))\n",
    "\n",
    "# 위 코드는 모든 주에 대한 집계를 계산한것이다.\n",
    "# 캘리포니아(CA)에 대해 보기를 원한다면?\n",
    "ca_count_mnm_df = (mnm_df\n",
    "                   .select('State', 'Color', 'Count')\n",
    "                   .where(mnm_df.State == 'CA')\n",
    "                   .groupBy('State', 'Color')\n",
    "                   .sum('Count')\n",
    "                   .orderBy('sum(Count)', ascending=False))\n",
    "\n",
    "ca_count_mnm_df.show(n=10, truncate=False)\n",
    "\n",
    "# SparkSession을 멈춘다\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26cc5d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c6b6b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05e32ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8000bbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998a7246",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfa5720",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efd9158",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e8fb3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e203af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f45f226",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dcc2f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611c470d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47570fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebaafd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb977d26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ce4a4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecafc43f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ec273d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d48936",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd69d9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7267bf9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79284ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfe897e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2ecf8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69951fa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ea6f3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052c9c49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
